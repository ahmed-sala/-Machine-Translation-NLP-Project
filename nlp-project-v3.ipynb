{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python [conda env:base] *",
   "name": "conda-base-py"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Requirements:\n",
    "# !pip install datasets transformers evaluate accelerate\n",
    "# !pip install sacrebleu\n",
    "# !pip install accelerate bitsandbytes\n",
    "# !pip install -U bitsandbytes\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from evaluate import load as load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "import warnings\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import scrolledtext\n",
    "warnings.filterwarnings(\"ignore\", message=\"Was asked to gather along dimension 0\")\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:10:55.564316Z",
     "iopub.execute_input": "2025-05-11T13:10:55.564631Z",
     "iopub.status.idle": "2025-05-11T13:12:38.132764Z",
     "shell.execute_reply.started": "2025-05-11T13:10:55.564603Z",
     "shell.execute_reply": "2025-05-11T13:12:38.131994Z"
    },
    "ExecuteTime": {
     "end_time": "2025-05-12T20:20:43.646823Z",
     "start_time": "2025-05-12T20:20:33.064342Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "MODEL_NAME    = \"Helsinki-NLP/opus-mt-ar-en\"\nMAX_SRC_LEN   = 128\nMAX_TGT_LEN   = 128\nBATCH_TRAIN   = 16\nBATCH_EVAL    = 16\nNUM_EPOCHS    = 2\nLEARNING_RATE = 5e-5\nOUTPUT_DIR    = \"./opus_mt_ar_en_full\"",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:12:38.134131Z",
     "iopub.execute_input": "2025-05-11T13:12:38.134628Z",
     "iopub.status.idle": "2025-05-11T13:12:38.139576Z",
     "shell.execute_reply.started": "2025-05-11T13:12:38.134610Z",
     "shell.execute_reply": "2025-05-11T13:12:38.138755Z"
    },
    "ExecuteTime": {
     "end_time": "2025-05-12T20:21:29.123982Z",
     "start_time": "2025-05-12T20:21:29.118921Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "train_ds = load_dataset(\"opus100\", \"ar-en\", split=\"train\")\neval_ds  = load_dataset(\"opus100\", \"ar-en\", split=\"validation\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:12:38.140241Z",
     "iopub.execute_input": "2025-05-11T13:12:38.140500Z",
     "iopub.status.idle": "2025-05-11T13:12:44.781082Z",
     "shell.execute_reply.started": "2025-05-11T13:12:38.140481Z",
     "shell.execute_reply": "2025-05-11T13:12:44.780527Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3fd8d1477e84fd0829dbb8b1c0e7835"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "test-00000-of-00001.parquet:   0%|          | 0.00/214k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49f092d646ef4f5aa20f0bef7c32adc5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/99.3M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5f3c969eb8243a789ec573651da4411"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "validation-00000-of-00001.parquet:   0%|          | 0.00/979k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b931eda4a0d54b5ab48f57617ffb0a7b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14c08f8f592b4b099038c25089c19854"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58bafac9922c43388bf6f6f0d028c0df"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "846a0bd8e9a64597b9f37510b8692121"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "print(\"=== Raw example ===\")\nprint(train_ds[0])  ",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:12:44.781706Z",
     "iopub.execute_input": "2025-05-11T13:12:44.781903Z",
     "iopub.status.idle": "2025-05-11T13:12:44.786364Z",
     "shell.execute_reply.started": "2025-05-11T13:12:44.781886Z",
     "shell.execute_reply": "2025-05-11T13:12:44.785443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "=== Raw example ===\n{'translation': {'ar': 'و هذه؟', 'en': 'And this?'}}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel     = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:12:44.788036Z",
     "iopub.execute_input": "2025-05-11T13:12:44.788236Z",
     "iopub.status.idle": "2025-05-11T13:12:50.253605Z",
     "shell.execute_reply.started": "2025-05-11T13:12:44.788220Z",
     "shell.execute_reply": "2025-05-11T13:12:50.252810Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5784a82c622245809663cfa95dfcc55d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30c4b8c278cd4e849660d073bf1b53f0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "source.spm:   0%|          | 0.00/917k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8113b6991c1d4aa4b3fdb38938dbe43d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9179e50aec2473395fa011200b97704"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14690d0ae35a44e7ada5c5e84c4fb6fa"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66e0813abb9b465192f945217ba427b7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bb4d91bf058426a844f7f8cb8f81db1"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "def preprocess(batch):\n    inputs = [ex[\"ar\"] for ex in batch[\"translation\"]]\n    targets = [ex[\"en\"] for ex in batch[\"translation\"]]\n    model_inputs = tokenizer(\n        inputs,\n        max_length=MAX_SRC_LEN,\n        truncation=True,\n        padding='max_length'\n    )\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            targets,\n            max_length=MAX_TGT_LEN,\n            truncation=True,\n            padding='max_length'\n        )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:12:50.254439Z",
     "iopub.execute_input": "2025-05-11T13:12:50.254675Z",
     "iopub.status.idle": "2025-05-11T13:12:50.259697Z",
     "shell.execute_reply.started": "2025-05-11T13:12:50.254648Z",
     "shell.execute_reply": "2025-05-11T13:12:50.259151Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "train_tokenized = train_ds.map(\n    preprocess,\n    batched=True,\n    remove_columns=[\"translation\"]\n)\neval_tokenized = eval_ds.map(\n    preprocess,\n    batched=True,\n    remove_columns=[\"translation\"]\n)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:12:50.260270Z",
     "iopub.execute_input": "2025-05-11T13:12:50.260487Z",
     "iopub.status.idle": "2025-05-11T13:17:06.672542Z",
     "shell.execute_reply.started": "2025-05-11T13:12:50.260454Z",
     "shell.execute_reply": "2025-05-11T13:17:06.671853Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/1000000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2dc973c499547e3a0b24716fdec8814"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "698ff1552cf54c74a4a6d1c752695d09"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d43671777cee4584a964b2c5b928d147"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:17:06.684184Z",
     "iopub.execute_input": "2025-05-11T13:17:06.684398Z",
     "iopub.status.idle": "2025-05-11T13:17:07.454582Z",
     "shell.execute_reply.started": "2025-05-11T13:17:06.684372Z",
     "shell.execute_reply": "2025-05-11T13:17:07.453847Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "batch = train_tokenized.select(range(4))   # first 4 examples\ncollated = data_collator(batch)\n\nprint(\"\\n=== Collated batch shapes ===\")\nfor k, v in collated.items():\n    print(f\"{k:15}: {v.shape}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T13:17:07.455427Z",
     "iopub.execute_input": "2025-05-11T13:17:07.455648Z",
     "iopub.status.idle": "2025-05-11T13:17:07.484413Z",
     "shell.execute_reply.started": "2025-05-11T13:17:07.455621Z",
     "shell.execute_reply": "2025-05-11T13:17:07.483737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\n=== Collated batch shapes ===\ninput_ids      : torch.Size([4, 128])\nattention_mask : torch.Size([4, 128])\nlabels         : torch.Size([4, 128])\ndecoder_input_ids: torch.Size([4, 128])\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "bleu_metric = load_metric(\"sacrebleu\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-10T23:35:23.678853Z",
     "iopub.execute_input": "2025-05-10T23:35:23.679087Z",
     "iopub.status.idle": "2025-05-10T23:35:25.293700Z",
     "shell.execute_reply.started": "2025-05-10T23:35:23.679064Z",
     "shell.execute_reply": "2025-05-10T23:35:25.293192Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5fca2d00c01455b931b4db12cc60629"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "276d0fe115b2433cb99dcc51930342ea"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    bleu = bleu_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=[[ref] for ref in decoded_labels]\n",
    "    )[\"score\"]\n",
    "    em_list = [int(p.strip() == l.strip()) for p, l in zip(decoded_preds, decoded_labels)]\n",
    "    acc = float(np.mean(em_list))\n",
    "    return {\"bleu\": bleu, \"exact_match_accuracy\": acc}"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-10T23:35:25.294363Z",
     "iopub.execute_input": "2025-05-10T23:35:25.294762Z",
     "iopub.status.idle": "2025-05-10T23:35:25.299913Z",
     "shell.execute_reply.started": "2025-05-10T23:35:25.294741Z",
     "shell.execute_reply": "2025-05-10T23:35:25.299238Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.model_max_length = MAX_SRC_LEN\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    generation_max_length=MAX_TGT_LEN,\n",
    "    generation_num_beams=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"bleu\",\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-10T23:35:25.302149Z",
     "iopub.execute_input": "2025-05-10T23:35:25.302399Z",
     "iopub.status.idle": "2025-05-10T23:35:25.346008Z",
     "shell.execute_reply.started": "2025-05-10T23:35:25.302384Z",
     "shell.execute_reply": "2025-05-10T23:35:25.345550Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized,\n    eval_dataset=eval_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-10T23:35:25.346600Z",
     "iopub.execute_input": "2025-05-10T23:35:25.346817Z",
     "iopub.status.idle": "2025-05-10T23:35:25.638810Z",
     "shell.execute_reply.started": "2025-05-10T23:35:25.346776Z",
     "shell.execute_reply": "2025-05-10T23:35:25.638169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_31/2917438852.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "trainer.train()\nfinal_metrics = trainer.evaluate()\nprint(\"Final evaluation metrics:\", final_metrics)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-10T23:35:25.639573Z",
     "iopub.execute_input": "2025-05-10T23:35:25.639862Z",
     "iopub.status.idle": "2025-05-11T08:33:34.426635Z",
     "shell.execute_reply.started": "2025-05-10T23:35:25.639836Z",
     "shell.execute_reply": "2025-05-11T08:33:34.426010Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [62500/62500 8:55:22, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Exact Match Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.160400</td>\n      <td>0.152615</td>\n      <td>39.837895</td>\n      <td>0.120000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.140600</td>\n      <td>0.149022</td>\n      <td>43.117302</td>\n      <td>0.129500</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[62833]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.encoder.embed_positions.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'lm_head.weight'].\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 02:32]\n    </div>\n    "
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Final evaluation metrics: {'eval_loss': 0.14902229607105255, 'eval_bleu': 43.11730207587384, 'eval_exact_match_accuracy': 0.1295, 'eval_runtime': 163.9332, 'eval_samples_per_second': 12.2, 'eval_steps_per_second': 0.384, 'epoch': 2.0}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "def translate_ar_to_en(text: str) -> str:\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=MAX_SRC_LEN\n    ).to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_length=MAX_TGT_LEN,\n        num_beams=5,\n        early_stopping=True\n    )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T08:33:34.427483Z",
     "iopub.execute_input": "2025-05-11T08:33:34.428192Z",
     "iopub.status.idle": "2025-05-11T08:33:34.432177Z",
     "shell.execute_reply.started": "2025-05-11T08:33:34.428165Z",
     "shell.execute_reply": "2025-05-11T08:33:34.431590Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "print(translate_ar_to_en(\"التعرف على الأنماط\"))\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T08:33:34.432894Z",
     "iopub.execute_input": "2025-05-11T08:33:34.433096Z",
     "iopub.status.idle": "2025-05-11T08:33:34.502059Z",
     "shell.execute_reply.started": "2025-05-11T08:33:34.433080Z",
     "shell.execute_reply": "2025-05-11T08:33:34.501520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Pattern recognition.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "save_path = \"/kaggle/working/helsenki_finetuned\"\n",
    "\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"Model and tokenizer saved to {save_path}\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T08:33:34.502740Z",
     "iopub.execute_input": "2025-05-11T08:33:34.502976Z",
     "iopub.status.idle": "2025-05-11T08:33:35.339467Z",
     "shell.execute_reply.started": "2025-05-11T08:33:34.502961Z",
     "shell.execute_reply": "2025-05-11T08:33:35.338667Z"
    },
    "ExecuteTime": {
     "end_time": "2025-05-11T13:30:33.565856Z",
     "start_time": "2025-05-11T13:30:32.924441Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/helsenki_finetuned\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_model(save_path)\n\u001B[0;32m      4\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39msave_pretrained(save_path)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel and tokenizer saved to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msave_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "def load_mt_model(model_dir: str = 'models/helsenki_finetuned'):\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir)\n",
    "    mdl = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "    return tok, mdl"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T08:33:35.340332Z",
     "iopub.execute_input": "2025-05-11T08:33:35.340937Z",
     "iopub.status.idle": "2025-05-11T08:33:35.344478Z",
     "shell.execute_reply.started": "2025-05-11T08:33:35.340912Z",
     "shell.execute_reply": "2025-05-11T08:33:35.343708Z"
    },
    "ExecuteTime": {
     "end_time": "2025-05-12T20:31:49.459611Z",
     "start_time": "2025-05-12T20:31:49.451960Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "def translate_ar_to_en(text: str, tokenizer, model) -> str:\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=MAX_SRC_LEN\n    ).to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_length=MAX_TGT_LEN,\n        num_beams=5,\n        early_stopping=True\n    )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T08:33:35.345258Z",
     "iopub.execute_input": "2025-05-11T08:33:35.345509Z",
     "iopub.status.idle": "2025-05-11T08:33:35.358554Z",
     "shell.execute_reply.started": "2025-05-11T08:33:35.345484Z",
     "shell.execute_reply": "2025-05-11T08:33:35.358018Z"
    },
    "ExecuteTime": {
     "end_time": "2025-05-12T20:32:20.467471Z",
     "start_time": "2025-05-12T20:32:20.463443Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "tok, mdl = load_mt_model()\n",
    "print(translate_ar_to_en(\"التعرف على الأنماط\", tok, mdl))\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T08:33:35.359263Z",
     "iopub.execute_input": "2025-05-11T08:33:35.359508Z",
     "iopub.status.idle": "2025-05-11T08:33:37.117818Z",
     "shell.execute_reply.started": "2025-05-11T08:33:35.359482Z",
     "shell.execute_reply": "2025-05-11T08:33:37.117088Z"
    },
    "ExecuteTime": {
     "end_time": "2025-05-11T15:05:53.991105Z",
     "start_time": "2025-05-11T15:05:52.839644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern recognition.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": "!zip -r file.zip /kaggle/working/helsenki_finetuned\nfrom IPython.display import FileLink\nFileLink(r'file.zip')",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-11T10:21:36.630453Z",
     "iopub.execute_input": "2025-05-11T10:21:36.630736Z",
     "iopub.status.idle": "2025-05-11T10:21:54.237577Z",
     "shell.execute_reply.started": "2025-05-11T10:21:36.630713Z",
     "shell.execute_reply": "2025-05-11T10:21:54.236850Z"
    },
    "ExecuteTime": {
     "end_time": "2025-05-11T15:02:43.709750Z",
     "start_time": "2025-05-11T15:02:43.544008Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "D:\\Nlp_project\\file.zip"
      ],
      "text/html": [
       "Path (<tt>file.zip</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "from tkinter import messagebox\n",
    "\n",
    "\n",
    "class TranslatorApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Arabic to English Translator\")\n",
    "        self.geometry(\"700x500\")\n",
    "        self.resizable(False, False)\n",
    "\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "            self.model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR)\n",
    "            self.model.eval()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Model Load Error\", f\"Failed to load model: {e}\")\n",
    "            self.destroy()\n",
    "            return\n",
    "\n",
    "        self._build_ui()\n",
    "\n",
    "    def _build_ui(self):\n",
    "        style = ttk.Style(self)\n",
    "        style.theme_use('clam')\n",
    "        style.configure('TButton', font=(\"Helvetica\", 10), padding=6)\n",
    "        style.configure('TLabel', font=(\"Helvetica\", 11))\n",
    "\n",
    "        input_frame = ttk.LabelFrame(self, text=\"Arabic Text\", padding=(10, 10))\n",
    "        input_frame.place(x=20, y=20, width=660, height=180)\n",
    "        self.input_text = scrolledtext.ScrolledText(input_frame, wrap=tk.WORD, font=(\"Segoe UI\", 10))\n",
    "        self.input_text.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        output_frame = ttk.LabelFrame(self, text=\"English Translation\", padding=(10, 10))\n",
    "        output_frame.place(x=20, y=260, width=660, height=180)\n",
    "        self.output_text = scrolledtext.ScrolledText(output_frame, wrap=tk.WORD, font=(\"Segoe UI\", 10), state='disabled')\n",
    "        self.output_text.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        btn_translate = ttk.Button(self, text=\"Translate\", command=self._on_translate)\n",
    "        btn_translate.place(x=300, y=215)\n",
    "        btn_clear = ttk.Button(self, text=\"Clear\", command=self._on_clear)\n",
    "        btn_clear.place(x=380, y=215)\n",
    "\n",
    "    def _on_translate(self):\n",
    "        arabic_text = self.input_text.get(\"1.0\", tk.END).strip()\n",
    "        print(f\"GUI Input: {repr(arabic_text)}\")  # Add this to see the exact input\n",
    "        if not arabic_text:\n",
    "            messagebox.showinfo(\"Input Required\", \"Please enter Arabic text to translate.\")\n",
    "            return\n",
    "        try:\n",
    "            translation = translate_ar_to_en(arabic_text, self.tokenizer, self.model)\n",
    "            self._display_translation(translation)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Translation Error\", str(e))\n",
    "\n",
    "    def _display_translation(self, text):\n",
    "        self.output_text.config(state='normal')\n",
    "        self.output_text.delete(\"1.0\", tk.END)\n",
    "        self.output_text.insert(tk.END, text)\n",
    "        self.output_text.config(state='disabled')\n",
    "\n",
    "    def _on_clear(self):\n",
    "        self.input_text.delete(\"1.0\", tk.END)\n",
    "        self.output_text.config(state='normal')\n",
    "        self.output_text.delete(\"1.0\", tk.END)\n",
    "        self.output_text.config(state='disabled')\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-05-12T20:32:23.431767Z",
     "start_time": "2025-05-12T20:32:23.418165Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:39:01.275398Z",
     "start_time": "2025-05-12T20:38:48.250598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    MODEL_DIR = 'models/helsenki_finetuned'\n",
    "\n",
    "    app = TranslatorApp()\n",
    "    app.mainloop()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUI Input: 'فوزى'\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:32:16.559734Z",
     "start_time": "2025-05-12T20:32:16.555208Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
